# 训练避障
**问题**：示教轨迹不包含障碍物，设存在一个圆形障碍在数据集轨迹上
**思路**：当靠近障碍物时，暂时忽略示教数据），只听从“避障”和“目标”的指挥。加权掩码 + 势场排斥
        ==**定义障碍物参数**==
        设系统状态为 $x \in \mathbb{R}^2$。我们有一个圆形的假设障碍物，定义为：**圆心**：$c \in \mathbb{R}^2$
    **半径**：$R > 0$**安全余量 (Safety Margin)**：$\delta > 0$**影响半径**：$R_{safe} = R + \delta$
        定义状态 $x$ 到障碍物中心的欧几里得距离为：$$d(x) = \| x - c \|_2$$我们的目标是学习一个 Koopman 算子 $K$ 和提升函数 $\Psi(x)$，使得预测的下一时刻状态 $\hat{x}_{k+1}$ 满足避障要求。
        **==可微模仿掩码==**
        需要一个权重函数 $w(x)\in[0,1]$，用于衡量我们对当前示教数据点 $(x_k ​ ,x_k+1)$ 的“信任度”。
                当$x_k$ 在障碍物安全区外 ($d(x_k) \gg R_{safe}$)：我们完全信任数据，希望 $w(x) \approx 1$。
                当 $x_k$ 在障碍物危险区内 ($d(x_k) < R_{safe}$)：数据是“错误”的（因为它会撞上障碍物），我们希望 $w(x) \approx 0$。
        为了保证训练时的梯度反向传播，我们使用 **Sigmoid 函数** 来构造这个平滑开关：$$w(x) = \sigma\left( \alpha \cdot (d(x) - R_{safe}) \right) = \frac{1}{1 + e^{-\alpha (d(x) - R_{safe})}}$$其中 $\alpha > 0$ 是一个超参数，控制开关的“陡峭”程度（$\alpha$ 越大，边界越清晰）。
                若 $d(x) = R_{safe}$，则 $w(x) = 0.5$（过渡带）。
                若 $d(x) < R_{safe}$（危险），指数项 $e^{-\alpha (\text{负数})}$ 变得很大，分母极大，$w(x) \to 0$。
                若 $d(x) > R_{safe}$（安全），指数项趋近 0，$w(x) \to 1$。
        **==排斥势能损失==**
        当掩码 $w(x) \to 0$ 时，模型不再模仿数据，此时我们需要一股新的损失函数来告诉模型“应该去哪”。这就是排斥损失。定义一个惩罚函数（Penetration Cost），只对进入安全半径内的点产生惩罚。使用 **ReLU (Rectified Linear Unit)** 函数来实现：$$\mathcal{L}_{rep}(x) = \left( \text{ReLU}(R_{safe} - d(x)) \right)^2$$推导分析：
                **情形 A**：安全 ($d(x) \ge R_{safe}$)$$\mathcal{L}_{rep}(x) = (\max(0, \le 0))^2 = 0$$梯度 $\nabla_x \mathcal{L}_{rep} = 0$。对模型没有影响。
                **情形 B**：危险 ($d(x) < R_{safe}$)$$\mathcal{L}_{rep}(x) = (R_{safe} - d(x))^2$$这是一个势能场。为了通过反向传播更新网络参数（即更新 $K$ 和 $\Psi$），我们需要看它对预测位置 $\hat{x}_{k+1}$ 的梯度：$$\nabla_{\hat{x}} \mathcal{L}_{rep} = 2(R_{safe} - \|\hat{x} - c\|) \cdot \nabla_{\hat{x}} ( -\|\hat{x} - c\| )$$利用链式法则 $\nabla_x \|x\| = \frac{x}{\|x\|}$：$$\nabla_{\hat{x}} \mathcal{L}_{rep} = -2(R_{safe} - d(\hat{x})) \cdot \frac{\hat{x} - c}{\|\hat{x} - c\|}$$**物理意义**：这个梯度方向是 $-(\hat{x} - c)$，即**背离障碍物圆心**的方向。
        **总损失函数的数学形式**
        结合 KoopMotion 原有的损失，新的总损失函数 $\mathcal{L}_{total}$ 为：$$\mathcal{L}_{total} = \beta_k \mathcal{L}_{masked\_koop} + \beta_{rep} \mathcal{L}_{rep} + \beta_g \mathcal{L}_{goal} + \beta_d \mathcal{L}_{div}$$
                **加权 Koopman 线性损失 ($\mathcal{L}_{masked\_koop}$)**： 只学习安全的轨迹段，忽略穿过障碍物的段。$$\mathcal{L}_{masked\_koop} = \frac{1}{N} \sum_{i=1}^{N} w(x_i) \cdot \| \Psi(x_{i+1}^{gt}) - K \Psi(x_i) \|_2^2$$
                **排斥损失 ($\mathcal{L}_{rep}$)**： 作用于模型预测的**下一步状态** $\hat{x}_{i+1}$（通过 $K\Psi(x_i)$ 恢复得到）。$$\mathcal{L}_{rep} = \frac{1}{N} \sum_{i=1}^{N} \left( \max(0, R_{safe} - \| \hat{x}_{i+1} - c \|_2) \right)^2$$
                **目标收敛损失 ($\mathcal{L}_{goal}$)**（原有）：$$\mathcal{L}_{goal} = \| (I - K) \Psi(x_{goal}) \|_2^2$$
                **散度损失 ($\mathcal{L}_{div}$)**（原有）：$$\mathcal{L}_{div} = \| \nabla \cdot F(x) \|_2^2$$
        当一个训练点 $x_k$ 位于障碍物边缘（危险区）时，模型参数 $\theta$ 会收到什么样的更新信号。总梯度为：$$\nabla_\theta \mathcal{L} \approx \beta_k \cdot w(x_k) \cdot \nabla_\theta \mathcal{L}_{koop} + \beta_{rep} \cdot \nabla_\theta \mathcal{L}_{rep} + \beta_g \cdot \nabla_\theta \mathcal{L}_{goal}$$在障碍物附近 ($w(x_k) \approx 0$)：
                第一项 $\approx 0$。模型不再试图去拟合那个“穿过圆心”的错误真值。
                第二项产生一个强烈的梯度，推动 $\hat{x}_{k+1}$ 往圆外跑。
                第三项（目标损失）和 Koopman 的全局特性依然存在，产生一个“向目标流动的趋势”。
                第四项（散度损失）强迫流场平滑。
        模型受到两个主要的力：一个推离障碍物（Repulsion），一个拉向目标（Goal）。由于 Koopman 算子（尤其是 RFF 提升后）本质上是在拟合一个连续的流场，为了同时满足这两个力且保持流场平滑（低散度），模型**只能**在障碍物周围“弯曲”流线，从而在数学上自动形成绕行轨迹。
        **补充**：
                为了让上述梯度生效，必须保证训练集覆盖了障碍物周围的区域。
                        我们需要构造一个**辅助数据集** $D_{aux}$：$$D_{aux} = \{ x \in \mathbb{R}^2 \mid R < \|x - c\| < R + \delta \}$$在训练的每个 Batch 中，除了取 LASA 数据点 $x_{lasa}$，还要从 $D_{aux}$ 中均匀采样 $x_{aux}$。 对于 $x_{aux}$，我们没有 $x_{t+1}^{gt}$，所以：
                                $\mathcal{L}_{masked\_koop}$ 不计算这些点（或 mask 设为 0）
                                **必须计算** $\mathcal{L}_{rep}$ 和 $\mathcal{L}_{goal}$。
                                我不知道这些点具体该往哪走（没有 ground truth），但我知道它们**绝不能**往圆内走（排斥损失），而且最终必须流向目标（目标损失）。

## 代码中如何开启避障训练

- `training_args.loss_weights.repulsion_weight`：控制势场排斥的权重，默认 0，避障时需要设为大于 0。
- `training_args.obstacle`：
  - `enabled`: 是否开启避障。
  - `center`、`radius`、`safety_margin`、`mask_alpha`: 定义圆形障碍物和可微掩码。
  - `auxiliary_batch_size`: 每个 batch 额外在安全带内采样的点数，用于只施加排斥/目标的梯度。

仓库中提供了示例配置 `scripts/configuration_files/lasa_angle_obstacle/model_config.yaml`，可直接运行 `run_main.py`（或自定义训练脚本）并指向该配置文件，自动生成含障碍的训练数据并学习绕障流场。
